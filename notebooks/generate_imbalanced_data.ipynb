{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Imbalanced Dataset\n",
    "\n",
    "Generates synthetic imbalanced classification datasets for XGBoost scaling experiments.\n",
    "\n",
    "**Parameters** (via widgets or job params):\n",
    "- `env`: Environment name (dev/prod)\n",
    "- `run_mode`: `full` or `smoke` (smoke uses tiny data for quick validation)\n",
    "- `json_params`: JSON string with additional config overrides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widget definitions - these can be overridden by job parameters\n",
    "dbutils.widgets.text(\"env\", \"dev\", \"Environment\")\n",
    "dbutils.widgets.dropdown(\"run_mode\", \"full\", [\"full\", \"smoke\"], \"Run Mode\")\n",
    "dbutils.widgets.text(\"json_params\", \"{}\", \"JSON Parameters\")\n",
    "\n",
    "# Catalog/schema widgets (can be set by job or bundle variables)\n",
    "dbutils.widgets.text(\"catalog\", \"brian_gen_ai\", \"Catalog\")\n",
    "dbutils.widgets.text(\"schema\", \"xgb_scaling\", \"Schema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Parse Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "# Add src to path for local imports\n",
    "# When deployed via DAB, the repo files are synced to workspace\n",
    "import os\n",
    "notebook_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "repo_root = \"/\".join(notebook_path.split(\"/\")[:-2])  # Go up from /notebooks/notebook_name\n",
    "sys.path.insert(0, f\"/Workspace{repo_root}\")\n",
    "\n",
    "# Import core logic\n",
    "from src.main import run, build_exit_result\n",
    "from src.config import DatasetConfig\n",
    "\n",
    "# Get widget values\n",
    "env = dbutils.widgets.get(\"env\")\n",
    "run_mode = dbutils.widgets.get(\"run_mode\")\n",
    "json_params = dbutils.widgets.get(\"json_params\")\n",
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "schema = dbutils.widgets.get(\"schema\")\n",
    "\n",
    "# Parse parameters and get config\n",
    "config = run(\n",
    "    env=env,\n",
    "    run_mode=run_mode,\n",
    "    json_params=json_params,\n",
    "    catalog=catalog,\n",
    "    schema=schema,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand, randn, when, col, lit\n",
    "from pyspark.sql.types import FloatType, IntegerType\n",
    "\n",
    "def generate_imbalanced_dataset(\n",
    "    spark,\n",
    "    total_rows: int,\n",
    "    n_features: int,\n",
    "    n_informative: int,\n",
    "    minority_ratio: float,\n",
    "    seed: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate large imbalanced classification dataset using Spark.\n",
    "    \n",
    "    - First n_informative features are correlated with target\n",
    "    - Remaining features are random noise\n",
    "    - Label is imbalanced with minority_ratio as positive class proportion\n",
    "    \"\"\"\n",
    "    print(f\"Generating: {total_rows:,} rows x {n_features} features\")\n",
    "    print(f\"  Informative features: {n_informative}\")\n",
    "    print(f\"  Minority ratio: {minority_ratio:.1%}\")\n",
    "    print()\n",
    "    \n",
    "    # Base dataframe with row IDs\n",
    "    df = spark.range(0, total_rows)\n",
    "    \n",
    "    # Imbalanced label (1 = minority class)\n",
    "    df = df.withColumn(\n",
    "        \"label\",\n",
    "        when(rand(seed) < minority_ratio, lit(1)).otherwise(lit(0)).cast(IntegerType())\n",
    "    )\n",
    "    \n",
    "    # Add features\n",
    "    for i in range(n_features):\n",
    "        feature_seed = seed + i + 1\n",
    "        \n",
    "        if i < n_informative:\n",
    "            # Informative: correlated with label\n",
    "            weight = 0.5 + (i % 10) * 0.15\n",
    "            df = df.withColumn(\n",
    "                f\"f{i}\",\n",
    "                (randn(feature_seed) + col(\"label\") * lit(weight)).cast(FloatType())\n",
    "            )\n",
    "        else:\n",
    "            # Noise: pure random\n",
    "            df = df.withColumn(f\"f{i}\", randn(feature_seed).cast(FloatType()))\n",
    "        \n",
    "        # Progress logging\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"  Added {i + 1}/{n_features} features...\")\n",
    "    \n",
    "    # Reorder: features first, then label\n",
    "    feature_cols = [f\"f{i}\" for i in range(n_features)]\n",
    "    return df.select(feature_cols + [\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset\n",
    "start_time = time.time()\n",
    "\n",
    "df = generate_imbalanced_dataset(\n",
    "    spark=spark,\n",
    "    total_rows=config.total_rows,\n",
    "    n_features=config.n_features,\n",
    "    n_informative=config.n_informative,\n",
    "    minority_ratio=config.minority_ratio,\n",
    "    seed=config.seed,\n",
    ")\n",
    "\n",
    "generation_time = time.time() - start_time\n",
    "print(f\"\\nDataFrame created in {generation_time:.1f}s (lazy - not materialized yet)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Writing to: {config.output_table}\")\n",
    "\n",
    "write_start = time.time()\n",
    "\n",
    "df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(config.output_table)\n",
    "\n",
    "write_time = time.time() - write_start\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(f\"Write completed in {write_time:.1f}s\")\n",
    "print(f\"Total time: {total_time:.1f}s ({total_time / 60:.1f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read back and validate\n",
    "df_check = spark.table(config.output_table)\n",
    "\n",
    "# Row count\n",
    "row_count = df_check.count()\n",
    "print(f\"Rows written: {row_count:,}\")\n",
    "print(f\"Expected:     {config.total_rows:,}\")\n",
    "print(f\"Match: {row_count == config.total_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "label_counts = df_check.groupBy(\"label\").count().orderBy(\"label\").collect()\n",
    "\n",
    "print(\"\\nClass distribution:\")\n",
    "class_distribution = {}\n",
    "for row in label_counts:\n",
    "    label = row[\"label\"]\n",
    "    count = row[\"count\"]\n",
    "    pct = count / row_count * 100\n",
    "    class_name = \"Minority\" if label == 1 else \"Majority\"\n",
    "    print(f\"  Label {label} ({class_name}): {count:,} ({pct:.2f}%)\")\n",
    "    class_distribution[label] = count\n",
    "\n",
    "if len(label_counts) == 2:\n",
    "    print(f\"\\nImbalance ratio: {label_counts[0]['count'] / label_counts[1]['count']:.1f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sample\n",
    "print(\"Sample data (first 5 rows, first 5 features + label):\")\n",
    "sample_cols = [f\"f{i}\" for i in range(min(5, config.n_features))] + [\"label\"]\n",
    "df_check.select(sample_cols).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exit with Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build result for job output\n",
    "result_json = build_exit_result(\n",
    "    config=config,\n",
    "    status=\"ok\",\n",
    "    row_count=row_count,\n",
    "    duration_seconds=total_time,\n",
    "    class_distribution=class_distribution,\n",
    ")\n",
    "\n",
    "print(f\"\\nNotebook result:\")\n",
    "print(result_json)\n",
    "\n",
    "# Exit with JSON result (fetchable via Databricks API)\n",
    "dbutils.notebook.exit(result_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
